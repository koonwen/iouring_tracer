* TODO
** IO_URING_TRACER
- [ ] Add on kprobes
- [ ] Plan out dynamic loading

** ocaml-libbpf
- [X] Build libbpf and hook into c_stubs (Try using ctypes)
- [X] Write OCaml bindings for libbpf

* Plan
** <2024-04-08 Mon>
*** AM
- [-] Figure out why C-thread cannot put events into the same ring
  buffer as user process
  ANS: It can, not a problem
  - [X] Get callbacks working in C
  - [X] Hook into bpf program without crashing
  - [X] Hook into olly
  - [X] Memlock limit, see if BPF still needs this increase explicitly
*** PM
- [X] Try to get one event written in from C
  - [X] Does C threading scheduler work pre-emptively or
    cooperatively?
    ANS: Pre-emptively. The system reserves the right
    to execute the yield command itself at any moment. In fact, it
    exercises this right sufficiently often to permit other threads to
    execute and to give the illusion that the threads are running in
    parallel, even on a uniprocessor machine.

  - [X] What happens when you don't grab the runtime lock?
    ANS: Only one thread at a time is allowed to run OCaml code on a
    particular domain, data races occur with undefined behaviour

** <2024-04-09 Tue>
*** AM
Fix IO_URING custom events not turining up in olly:
- [X] Try on simple custom event
  Ans: Yes you can see the events. Don't build with dune because it
  won't capture your program. There is a chance that events will be
  overwritten but olly will print this to stderr.

- [X] Look through olly implementation. What runtime buffer is being
  recorded? Does it track different threads

  Ans: all threads and ringbuffers are captured.  Need to watch out
  for the format type you are using fuchsia will capture all event
  Type's but json will only catch span's

- [X] Name the events
- [X] Write spans for syscalls (unpolished)

*** PM:
- [X] Write a test harness for watch mode and also to run your program
- [X] Does the bpf ring buffer drop messages?
  Ans: No

** <2024-04-10 Wed>
*** AM
- [X] Fix up development env for laptop
- [X] Produce some artifacts using custom events
  - [X] Interactive
  - [X] Against read_async.exe
  - [X] Against eio copy program
  - [X] Update README
*** PM
- [X] Add in graceful shutdown (initial work)

** <2024-04-11 Thu>
*** AM
- [X] Reply Tim about adding USDT probes
  ANS: Yes libbpf has API's to attach USDT probes.

*** PM
- [X] Investigate why there are recursive syscalls (programming error)
  Ans: with olly trace json, and interactive run, it looks like the
  callbacks are firing in the right linear order. olly trace fuchsia
  may be recording the events weirdly.

** <2024-04-12 Fri>
*** AM
- [X] Debug recursive events
  - [X] Try querying sql slices in perfetto

    ANS: Says that the time slice of the earlier call is greater and
    therefore causes the depth to increase by 1.

    Looks like the timestamps are clobbering each other. eio ts
    spans are taking on the ts recorded by the syscalls

*** PM
 - [X] Dive into runtime events implementation & olly

    ANS: timestamps are recorded in the runtime itself

  - [X] See if you can store events going into trace to debug (pin local olly)

    ANS: callback ordering is correct but issue still persists.


** <2024-04-15 Mon>
*** AM:
- Re-support separate processes for probe and user program
  - [X] Test with OCaml process that just runs bpf c program. See if
    runtime events buffer can consume events external bpf program.
  - [X] See what timestamping looks like

*** PM:
- [X] ocaml-libbpf
  - [X] Work on supporting get version stub.

** <2024-04-16 Tue>
*** AM
- [-] Continued work on libbpf
  - [ ] How does typing work in libbpf?

    ANS: size_t is the maximum addressable size of the running
    machine. It varies depending on the size of the machine word of
    the machines.

  - [X] How do you typically pass pointers into OCaml
    ANS: Not sure but can use ctypes
  - [X] Understand the header file for libbpf.h
    - [X] What does LIBBPF_API macro do
      ANS: It's just standard practice for visibility to user
    - [X] Where are the types in libbpf.h defined
      ANS: in /usr/include/linux/bpf.h

  - [-] Work toward first supporting libbpf.h & bpf_helpers.h
    - [X] libbpf_strerror
    - [ ] libbpf_bpf_attach_type_str
    - [ ] libbpf_bpf_link_type_str
      the attach_type_str functions are not that useful

    - [X] struct bpf_object
    - [X] bpf_object__open_file

*** PM
- Meeting
**** Work done recap
1. Experimented single process, multi-threaded design for getting
   probe events into same runtime buffer as OCaml user program.
2. Also experimented with multi-process, single-threaded design.
3. Hook them up with olly & testing against eio program.
4. Debugging why there are recursive syscall events recorded
   (shouldn't be the case). [Unresolved]
   Steps taken:
   - Checked if it's a programming error by injecting some printf's
     into olly to see that callbacks are fired in order. Open and close
     match and there are no double opens before we see a close.
   - Noticed that the events are only recorded in recursive fashion
     when run with fuchsia format but not with json.
   - Timestamps in perfetto show that the eio.suspend_domain event
     gets mixed up with our SYS_IO_URING_ENTER event, causing it to
     read as a recursive span. Suspect that the event registration
     ID's might overlap with each other. Changed the registration
     order but this also had no effect.
   - Spans in Fuchsia match on names? Docs are unclear, source code
     also impenetrable.
   - No tools other than perfetto for debug fuchsia format, took a
     stab at reading the binary but didn't manage to get anything out
     of that.
5. Initial work on libbpf c-bindings

**** Trade-off discussion for probe reader design
#Design1: OCaml user process + C thread w callback write to custom events
   (current implementation)

Advantages:
- Enable user to write custom bpf event callback handlers directly in
  their user program
- Supports direct usage with olly.

Disadvantages:
- Won't be able to avoid running OCaml program with root access
  because bpf programs require sudo permissions.
- Timestamps are inaccurate because they reflect when events are added
  into the ring buffer, rather than the actual time they were
  triggered. i.e. timestamps are subject to poll points when the OCaml
  user process gives up the runtime lock.

#Design2: OCaml probe process + OCaml user process + add support in olly to
   consume events from both

Advantages:
- May be possible to restrict root privileges only to the probing process
- Timestamping may be more accurate because they go into the runtime
  buffer closer to real time.

Disadvantages:
- Lining up the timestamps across processes may be non-trivial since
  they are recorded not on real-time but against the start of the
  OCaml process.
- lose the program-ability of custom bpf event handlers in the user
  program.
- requires changes to be made to olly. (In which case, we may want to
  merge the probing program directly into the olly repo)

**** libbpf stubs
- standalone library build works with dune. Any advice and convention
  for dealing with type conversions between OCaml and kernel types?
  size_t? pointers?

[208343733565115 s] rb_idx:0 (SYS_IO_URING_ENTER) BEGIN (1 open)
[208343733584743 s] rb_idx:0 (eio.suspend_domain) BEGIN (2 open)
[208343733588991 s] rb_idx:0 (SYS_IO_URING_ENTER) END   (2 close)
[208343733589141 s] rb_idx:0 (SYS_IO_URING_ENTER) BEGIN (3 open)
[208343733651008 s] rb_idx:0 (eio.suspend_domain) END   (3 close)
[208343733683259 s] rb_idx:0 (SYS_IO_URING_ENTER) END   (1 close)
   - Even when using multiple processes, recursive events are
     still appearing even though the ordering does not indicate it.

**** Other questions
- Should I ping Anil for the programs to debug?
**** TODO
Suggestions:
- emit events with fuchsia. eio_dump.
- The timestamps are based on clock_monotonic, since the system was
  booted. Should be no issue across multiple domains recording events.
- Talk to Beatrice about runtime_events tracing

bpf events use cases:
1. Check against eio programs.
2. Write bpftrace script that can give the data.

bpf events design & implementation:
1. Port eio fuchsia format to the project and emit directly.
3. Merge two trace formats.
2. Get tracing dependency out of olly.

**** Notes
When writing bpf kernel code, the SEC macro (short for section) is
used to define what libbpf program should create and how/where to
attach it in the kernel.

BPF CO-RE is a new step toward portability since BCC. Portability is
difficult with BPF because the kernel is constantly changing it's
memory layout, types can be renamed, structs can change. Using BCC
would embed your BPF program as a string and then compile them on the
fly on your production machine using CLANG and the system kernel
headers. But this is costly (size and time wise) and has a slow
iteration cycle.

BPF CO-RE relies on using BTF type information from both the BPF
program and the kernel to work out type discrepancies between
them. Libbpf works as a loader to tie the BTFs from the kernel and the
program and adjust the compiled BPF code to the specific kernel.

The user program API's for libbpf are found in public headers:
libbpf.h
bpf.h
btf.h

** <2024-04-17 Wed>
*** AM
- [-] Get usable bpftrace cmdline tool against custom script
  - [X] Update driver (support interactive use, remove runtime_events cruft)
  - [X] Fix cmdline usage of trace to be interactive
  - [X] Set up easy way to load different bt scripts
  - [X] Test against EIO http use case.

** <2024-04-18 Thu>
*** AM
- Digest Missing Manuals IO_uring & investigate slowness
  - [X] Where does asynchronous work come in io_uring runtime

    ANS: The spawning of io_workers are dependent on the type of io
    work called. If the io request has a non-blocking option, it
    preferentially takes the code path that calls this and sets a
    wakeup notification to read when it's done. No new worker thread
    is spawned. However, if the IO request only has a blocking api,
    then this code path spawns new worker threads to concurrently
    process the blocking requests.

    However, if you want to force uring to use the blocking path to
    spawn worker threads, this is possible by marking requests into
    uring as IOSQE_ASYNC which tells it to issue requests
    asynchronously.

    The other aspect to consider is the number of workers that uring
    will spawn in response. Uring describes how it automatically
    determines this. But we can also manually set the number of max
    workers using IO_URING_REGISTER_IOWQ_MAXWORKERS.

    There are other ways to set this limit which requires setting
    RLIMIT_NPROC or configuring cgroup process limit.

  - [X] show if worker threads are created

*** PM
  - [X] try to spawn more worker threads.
    ANS: liburing doesn't seem to allow us to configure spawning
    worker threads.

  - [X] figure out why there are lost events

    ANS: bpftrace user program is single threaded and processes events
    one by one, the kernel side buffer therefore drops events because
    it the user side cannot clear the buffer fast enough. We can
    increase the size of the kernel buffer by increasing
    BPFTRACE_PERF_RB_PAGES config variable.

** <2024-04-19 Fri>
*** AM
  - [X] Convert loading of bt files via paths so that config variables
    work.
    - ANS: It doesn't matter if it's by script or inline, both don't work
  - [X] Submit Weeklies

*** PM
  - [X] Add in config params to bpftrace



** <2024-04-22 Mon>
*** AM
- [X] Port eio fuchsia format to the project and emit directly.
  - [X] Swap out serialization engine to use Faraday
  - [X] Hook up with lwt loop

*** PM
- [X] Port contd.
- [X] Write bpftrace script showing depth
**** Notes
liburing usage optimization:
https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023

** <2024-04-23 Tue>
*** AM
- [X] bpftrace with depth
  - [X] Get timestamping correct
- [X] Check if the print format provided in the event spec can be used
  directly
- [X] Fix timestamp for libbpf version

*** PM
- [X] Merging Fuchsia trace formats
  - ANS: Just a simple cat. But perfetto sometimes messes up the
    spans, so it's a good idea to make sure the thread id or category
    is different
- [X] See if you can use libtrace directly
  - ANS: looks hard to extract.

** <2024-04-24 Wed>
*** AM
- [X] Add more bpftrace programs
  - [X] uring_spans: depth log
  - [X] uring_ops: op count & time
  - [X] uring_strace_summary: summary of syscalls on multiple ring instances
  - [X] uring_tp_strace: strace-like output

*** PM
- [ ] Parsing for bpftrace output for nicer printing

** <2024-04-25 Thu>
Hacking days
*** AM
- [X] Pick a task
  ANS: Chose ocaml-crunch project
- [X] Read about how its done in paper
- [X] Review how its done in rust & golang
- [X] See how it's done in ocaml-crunch

*** PM
**** Meeting
***** Work done
- Port eio_trace fuchsia format writer into our project.
- Write strace & strace summary equivalent bpf scripts for bpftrace
- Investigate io-uring performance intricacies

***** For discussion
- What to prioritize?
  1. Write more bpftrace scripts for tracing uring
     - Good: Simple, fast, effective
     - Bad: Not much of an OCaml library, really just a collection of
       scripts. Cannot output fxt, not extensible
  2. Work on libbpf bindings for backend supporting tracing & bpf
     usage
     - Good: extensible, can integrate directly into OCaml.
     - Bad: A lot more work to get the same results as bpftrace

- Performance engineering questions for io-uring
  - Are eio fibers seen as systhreads? Not recommended to share a
    io-uring instance between multiple threads.
    https://github.com/axboe/liburing/issues/571#issuecomment-1106480309)
  - How much faster performance are we expecting? Online benchmarks
    are divided on whether io-uring is strictly faster than
    epoll. Looks like we have baseline expectations for read & writes
    for the uring bindings but they aren't compared against posix
    backends. We should probably look at doing those first before
    trying speed up eio?
  - syscall latency wise, even though we have substantially less
    syscalls, the time spent inside them is still overall about same
    as posix backends. On my machine however, as the number of domains
    go up, the throughput increases in favour of io-uring. At low core
    counts, performance can dip worse than posix


***** Integrate eio_trace fuchsia format writer into uring trace library
- Hacky, swapped out serialization engine from eio to faraday
  because needed to register a callback and I'm not sure if it's
  possible with eio's capabilities design pattern. Also uses lwt as
  backend to manage concurrency, may want to do a rewrite of this to
  use effects

***** Write OCaml frontend for bpftrace usage
- Make it easy to drop-in different bpftrace scripts to be loaded &
  run

***** Investigating io-uring performance on eio http server
- Question: How much faster performance are we expecting? Online
  benchmarks are divided on whether io-uring is strictly faster than
  epoll.

- `strace -c` shows that syscall count for io-uring is substantially
  lower but the time spent per call is slower. total time spent in
  kernel ends up being almost identical.

- I'm interested in bench-marking purely the uring bindings and see if
  there optimization is there. It seems like there a bunch of knobs to
  twiddle when it comes to using uring effectively but those choices
  are abstracted by the uring bindings.

** <2024-04-26 Fri>
*** AM
- [X] Try to get original tracer to register callback
- [ ] Debug Fuchsia trace not being written.
  ANS: Uncompleted, consolidated and asked for suggestions

*** PM
- [X] Work on libbpf bindings
  - [X] Work on the enums for the libbpf_set_strict_mode ANS: flagsets
    aren't well supported by ctypes, only allowed to pass one flag
    instead of a list
  - [X] Work on bpf_object__open
    ANS: Works for loading an object file
    but not sure if the memory is allocated correctly
  - [X] Work on bpf_object__load
    ANS: Implementation works, Load performs implicit increase in RLIMIT_MEMLOCK


** <2024-04-29 Mon>
*** AM
- [X] Complete libbpf bindings surface area
  - [X] libbpf_bpf_get_error
  - [X] bpf_object__find_program_by_name
  - [X] bpf_object__next_program
  - [X] bpf_program__attach
  - [X] bpf_object__find_map_by_name
  - [X] bpf_map__fd
  - [X] bpf_link__destroy
  - [X] bpf_object__close
  - [X] ring_buffer__new
  - [X] ring_buffer__poll
  - [X] ring_buffer__free
- [X] Get working OCaml user program

  ANS: Needed to indicate to Foreign.funptr that optional
  ~runtime_lock:true so that in the callback it reacquires the runtime
  lock

*** PM
- [X] Port iouring_tracer to use libbpf bindings
  - [X] Get structs mapping working in Ctypes
  - [X] Get Fxt writer working

** <2024-04-30 Tue>
*** AM
- [X] Fix timestamping

*** PM
- [-] Investigating user/kernel time difference (kernel time is the
  same, but posix backend is slower in user space)
  - [X] Disable the mitigation's & run (Expectation is that posix
    backend should catch up)

    ANS: Yes expectations meet, posix backend
    does get closer to linux time but for some reason, user time
    increases?

**** Results
  Mitigations off: Warmup 10

  POSIX
  2C, 2S:
  Time (mean ± σ):     169.3 ms ±  21.6 ms    [User: 240.0 ms, System: 214.5 ms]
  Range (min … max):   135.3 ms … 221.5 ms    20 runs

  "name": "requests:50000 client-domains:2 server-domains:2",
  "value": 311506.948611763,
  "units": "requests/s",

  4C, 4S:
  Time (mean ± σ):     272.1 ms ±  15.0 ms    [User: 634.8 ms, System: 604.0 ms]
  Range (min … max):   248.6 ms … 293.0 ms    11 runs

  "name": "requests:100000 client-domains:4 server-domains:4",
  "value": 413993.015731384,
  "units": "requests/s"

  8C, 8S:
  Time (mean ± σ):     470.8 ms ±  41.4 ms    [User: 2063.9 ms, System: 1729.7 ms]
  Range (min … max):   415.5 ms … 553.6 ms    10 runs

  "name": "requests:100000 client-domains:4 server-domains:4",
  "value": 413993.015731384,
  "units": "requests/s"

  16C, 16S:
  Time (mean ± σ):     609.9 ms ±  43.3 ms    [User: 6673.5 ms, System: 4555.6 ms]
  Range (min … max):   549.3 ms … 690.3 ms    10 runs

  "name": "requests:400000 client-domains:16 server-domains:16",
  "value": 686330.1100192188,
  "units": "requests/s"

real	0m0.542s
user	0m6.002s
sys	0m4.781s

% time     seconds  usecs/call     calls    errors syscall
------ ----------- ----------- --------- --------- ------------------
 33.20    1.037025          45     23000           writev
 29.75    0.929072         538      1726         7 futex
 22.02    0.687665          14     46042     23019 readv
 11.61    0.362660        2948       123           clock_nanosleep
  3.33    0.103931          20      5131           ppoll
  0.03    0.000916          17        52           fcntl
  0.02    0.000751          30        25         2 accept4
  0.01    0.000410           7        54           mmap
  0.01    0.000378          47         8           munmap
  0.01    0.000285           9        31           close
  0.00    0.000124           6        18           write
  0.00    0.000018           3         6           read
  0.00    0.000007           7         1           sched_getaffinity
  0.00    0.000005           1         3           sigaltstack
  0.00    0.000000           0         4         4 lseek
  0.00    0.000000           0        36           mprotect
  0.00    0.000000           0         7           brk
  0.00    0.000000           0         5           rt_sigaction
  0.00    0.000000           0       134           rt_sigprocmask
  0.00    0.000000           0         1           rt_sigreturn
  0.00    0.000000           0         2           pread64
  0.00    0.000000           0         1         1 access
  0.00    0.000000           0         1           socket
  0.00    0.000000           0         1           bind
  0.00    0.000000           0         1           listen
  0.00    0.000000           0         1           setsockopt
  0.00    0.000000           0         1           execve
  0.00    0.000000           0         1           readlink
  0.00    0.000000           0         1           arch_prctl
  0.00    0.000000           0         1           set_tid_address
  0.00    0.000000           0         3           openat
  0.00    0.000000           0         5           newfstatat
  0.00    0.000000           0         1           set_robust_list
  0.00    0.000000           0         2           pipe2
  0.00    0.000000           0         5           prlimit64
  0.00    0.000000           0         1           getrandom
  0.00    0.000000           0         1           rseq
  0.00    0.000000           0        33           clone3
------ ----------- ----------- --------- --------- ------------------
100.00    3.123247          40     76469     23033 total

  ==============================================================================

  LINUX
  2C, 2S
  Time (mean ± σ):     196.6 ms ±  19.4 ms    [User: 153.9 ms, System: 370.1 ms]
  Range (min … max):   154.6 ms … 236.1 ms    14 runs

  "name": "requests:50000 client-domains:2 server-domains:2",
  "value": 271570.9050412442,
  "units": "requests/s",

  4C, 4S
  Time (mean ± σ):     247.0 ms ±  16.2 ms    [User: 358.4 ms, System: 763.9 ms]
  Range (min … max):   229.3 ms … 270.8 ms    11 runs

  "name": "requests:100000 client-domains:4 server-domains:4",
  "value": 480773.76728980854,
  "units": "requests/s"

  8C, 8S
  Time (mean ± σ):     343.9 ms ±  35.5 ms    [User: 947.4 ms, System: 1710.9 ms]
  Range (min … max):   289.4 ms … 400.4 ms    10 runs

  "name": "requests:200000 client-domains:8 server-domains:8",
  "value": 609663.3503907508,
  "units": "requests/s"

  16C, 16S
  Time (mean ± σ):     520.8 ms ±  40.4 ms    [User: 3315.9 ms, System: 4743.2 ms]
  Range (min … max):   475.8 ms … 617.9 ms    10 runs

  "name": "requests:400000 client-domains:16 server-domains:16",
  "value": 978569.7329134545,
  "units": "requests/s"

real	0m0.411s
user	0m3.290s
sys	0m4.751s

% time     seconds  usecs/call     calls    errors syscall
------ ----------- ----------- --------- --------- ------------------
 67.78    2.155765        1563      1379           io_uring_enter
 17.46    0.555269         486      1141        98 futex
 10.96    0.348594        3084       113        10 clock_nanosleep
  3.68    0.116914        4031        29        19 restart_syscall
  0.04    0.001144         143         8           brk
  0.02    0.000654           4       131           rt_sigprocmask
  0.02    0.000637          19        33           clone3
  0.02    0.000558           9        56           mmap
  0.02    0.000514          13        38           close
  0.01    0.000329           9        36           mprotect
  0.01    0.000182          10        18           write
  0.00    0.000000           0         3           read
  0.00    0.000000           0         4         4 lseek
  0.00    0.000000           0        10           munmap
  0.00    0.000000           0         4           rt_sigaction
  0.00    0.000000           0         2           pread64
  0.00    0.000000           0         1         1 access
  0.00    0.000000           0         1           socket
  0.00    0.000000           0         1           bind
  0.00    0.000000           0         1           listen
  0.00    0.000000           0         1           setsockopt
  0.00    0.000000           0         1           execve
  0.00    0.000000           0         1           readlink
  0.00    0.000000           0         3           sigaltstack
  0.00    0.000000           0         1           arch_prctl
  0.00    0.000000           0         1           sched_getaffinity
  0.00    0.000000           0         1           set_tid_address
  0.00    0.000000           0         3           openat
  0.00    0.000000           0         5           newfstatat
  0.00    0.000000           0         1           set_robust_list
  0.00    0.000000           0         1           eventfd2
  0.00    0.000000           0         1           pipe2
  0.00    0.000000           0         4           prlimit64
  0.00    0.000000           0         1           getrandom
  0.00    0.000000           0         1           rseq
  0.00    0.000000           0         1           io_uring_setup
  0.00    0.000000           0         2           io_uring_register
------ ----------- ----------- --------- --------- ------------------
100.00    3.180560        1046      3038       132 total

** <2024-05-02 Thu>
*** AM
- [-] Investigating user/kernel time difference (kernel time is the
  same, but posix backend is slower in user space)
  - [X] Try perf to see the user space slowness. (need frame pointers)

    ANS: Culprit is Iomux.Poll.loop, presumably busy waiting on
    events.
  - [ ] Use magic trace to see where the time is being spent (only on intel machine)

*** PM
Meeting
- [ ] Fix types & tid

** <2024-05-03 Fri>
*** AM
- [X] Read up about eio & eio-trace


** <2024-05-06 Mon>
*** AM
- [X] Figure out why uring is slower on AMD machine?
  - [X] Get benchmark results for AMD vs Intel
  - [X] How to tally up time summed up by 'time' command
  - [X] Use strace -c to get breakdown in timings
  - [X] Check percentage time spent for IO-uring enter in AMD vs Intel

linux time AMD
Average real time: 0.1938
Average user time: 0.1625 : 29.08%
Average sys time: 0.3967  : 70.92%
 -> Seconds in syscalls: 0.28
 -> Seconds  ctx-switch: 0.12

linux time Intel
Average real time: 0.4567
Average user time: 0.8132 : 51.53%
Average sys time: 0.7646  : 48.47%
 -> Seconds in syscalls: 0.30
 -> Seconds  ctx-switch: 0.46

posix time AMD
Average real time: 0.1876
Average user time: 0.2406 : 44.80%
Average sys time: 0.2966  : 55.20%
 -> Seconds in syscalls: 0.28
 -> Seconds  ctx-switch: 0.02

posix time Intel
Average real time: 0.6426
Average user time: 1.2126 : 57.29%
Average sys time: 0.9038  : 42.71%
 -> Seconds in syscalls: 0.58 (Instrumentation of strace -c seems sporadic)
 -> Seconds  ctx-switch: 0.32

2C 2S
From Intel to AMD linux
~4.6x faster in user time
~1.9x faster in sys time

2C 2S Mit on
From Intel to AMD posix
~4.7x faster in user time
~3.3x faster in sys time

2C 2S Mit off
From Intel to AMD linux
~3x user
~1.4x sys

From Intel to AMD posix
~3x user
~2.3x sys


2C 1S
From Intel to AMD linux
~3.3x faster in user time
~1.5x faster in sys time

2C 1S
From Intel to AMD posix
~3.5x faster in user time
~2x faster in sys time

1C 2S
From Intel to AMD linux
~3.7x faster in user time
~1.2x faster in sys time

From Intel to AMD posix
~4.5x faster in user time
~2.5x faster in sys time

Hypothesis, sys time doesn't seem to scale proportionately. Breakdown
of sys time shows that there is a significant proportion of time spent
in ctx-switch. SQPOLL requires kernel thread, on 4 core system,
running 4 domains means that scheduler needs to juggle 5 system threads.

3 domains, because SQPOLL uses 1 kernel thread, 10,000 total req
linux time Intel
Average real time: 0.537
Average user time: 0.7407
Average sys time: 0.71195
 -> Seconds in syscalls: 0.38 : 53%
 -> Seconds  ctx-switch: 0.33 : 47%

linux time AMD

From Intel to AMD linux
~ faster in user time
~ faster in sys time

From Intel to AMD posix
~ faster in user time
~ faster in sys time

# posix time Intel
# Average real time: 0.62365
# Average user time: 1.06125
# Average sys time: 0.84345
#  -> Seconds in syscalls: 0.54 (Instrumentation of strace -c seems sporadic)
#  -> Seconds  ctx-switch: 0.3

16 domains + SQPOLL
linux
Average sys time: 2.0389
 -> Seconds in syscalls: 1.39 : 68%
 -> Seconds  ctx-switch: 0.65 : 32%

# posix
# Average sys time: 2.0571
#  -> Seconds in syscalls: 1.24 (Instrumentation of strace -c seems sporadic)
#  -> Seconds  ctx-switch: 0.82

32 domains + SQPOLL, should see ctx switch taking a hit
linux time AMD
Average real time: 0.5877
Average user time: 3.0304
Average sys time: 5.4765
 -> Seconds in syscalls: 3.62672 : 66%
 -> Seconds  ctx-switch: 1.84978 : 34%

# posix time AMD
# Average real time: 0.6453
# Average user time: 6.6847
# Average sys time: 5.2019
#  -> Seconds in syscalls: 3.33483 (Instrumentation of strace -c seems sporadic)
#  -> Seconds  ctx-switch: 1.86707

*** PM
- [ ] Fix typing and ID-ing the of span events

** <2024-05-07 Tue>
*** AM
- [X] Create spans view of ops using libbpf
  - [X] Implement kernel side
  - [X] Support user side
  - [ ] Start working on portability, using compile-once
    run-everywhere standard,

** <2024-05-10 Fri>
- [ ] Double check benchmarks

  2C 2S Linux
  Intel: 408ms
  AMD: 160ms
  ~2.55x faster

  1C 2S
  Intel: 259ms
  AMD: 126ms
  ~2x faster

  2S 1C
  Intel: 553ms
  AMD: 255ms
  ~2.2x faster

  1C 1S
  Intel: 265ms
  AMD: 156ms
  ~1.7x faster

No clear reason

  2C 2S intel - AMD linux
  mit off
  Intel  linux [User:550ms, Sys:651ms]
  Intel  posix [User:830ms, Sys:647ms]

  Intel  linux [User:800ms, Sys:770ms]
  Intel  posix [User:1370ms, Sys:930ms]

  AMD    linux [User:160ms, Sys:430ms]
  AMD    posix [User:240ms, Sys:270ms]

  mit off
  Intel/AMD  linux [~3.4x user, 1.5x sys]
  Intel/AMD  posix [~3.5x user, 2.4x sys]

  Intel/AMD  linux [~5x user, 1.8x sys] 50/50
  Intel/AMD  posix [~5.7x user, 3.4x sys] 60/40




** <2024-05-13 Mon>
- [X] Post last weeks updates
** <2024-05-14 Tue>
- [X] Anil's benchmarks
  - [X] Write program for creating random synthetic fs
** <2024-05-15 Wed>
- [-] Anil's benchmarks
  - [X] Add on C code for stat vs statx
  - [ ] Work on syscalls vs uring

** <2024-05-16 Thu>
*** AM
  - [X] Share progress report

*** PM
**** TODO
- [X] Figure out why uring is slower on AMD machine?

  Performance factors:
  1. Cheaper syscalls, shows a more pronounced improvement in posix than linux
  2. Number of syscalls, Favours linux over posix

  Moving from Intel to AMD, effect of (1) overshadows (2) for that
  specific workload. This is because on small workloads, improvements
  by (2) is less significant in comparison to (1).

- [X] Figure out what kind of bpf programs would be useful for eio
  - [X] Implement a spans version of ops
  ...

I've put that aside
- [-] Our library could enable parameterisation of the programs to include
  (could just work as a case statement & the compiler will remove dead
  code paths)
  - [X] User side: Experiment with middleware-like opt-in events.
  - [ ] Kernel side:
    - Share ring buffer, issue is that it's quite easy
      to overflow the buffer, we need a good way to report this to the
      user or better way of handling it in user land.
    - Spawning separate programs also not a good idea because tracer
      ends up tracking those processes to track

      Suggestion: Keep a counter of in kernel that increments everytime an
      event cannot be reserved, query at the end of the trace

- [-] Work on Anil's benchmarks in uring repo.
  - [X] Implement synthetic filesystem generator
    - [X] Parameterised by depth of dirs, number of files/dir, size of files
    - [X] Currently randomly generates an fs given those params
  - [X] stat vs statx
    Benchmark: run stat vs statx(grab all params) vs statx(grab 1 param) million times over a file
    ANS: Cost is relatively the same:
  - [X] uring vs syscalls Benchmark: Run sequential stat vs uring
    sequential stat vs uring batched. Structually the uring code will
    be different than the syscalls

    ANS: uring batched was the fastest

  - [ ] Uring only: linked req vs independent req
    - Wouldn't enforcing any kind of ordering just be a slowdown.

  - [ ] Uring only: optimal buffer size
    - Not sure what this buffer is for? For holding that stat data? Or
      any data? This is tied to the size of the queue?

  - [ ] Subdir traversal

- [ ] Extract fxt tracing into standalone library

** <2024-05-17 Fri>
*** AM
  - [X] Benchmarks
    - [X] Update Anil and check what fields are required for the diff
    - [X] Create new repo and port eio fs_gen
      - [X] Keep notes for filesystem benchmarking for blogpost
      - [X] Do C benchmarks instead of OCaml
    - [X] Consolidate stat tests under the same program with
      switchable params
    - [X] Use Hyperfine with warmup for benchmarking (Note Freq scaling / Power)
      - [X] Account for Freq scaling with warmup runs
      - [X] Account for caching by clearing cache before each run




** <2024-05-21 Tue>
*** AM
- [X] Benchmarks
  - [X] Read up on available batching mechanisms
    ANS: Outer while loop and two inner while loop (1st inner adds to sqe until no more space) (2nd reaps at least 1 completion)
  - [X] Psudeo-code for batched walk
    - [X] Figure out how to use provided buffers to store & allocate buffers (struct for shared resources)
      ANS: liburing manages the allocation of cqe's and sqe's so we only need to preallocate the user_data buffers.
    - [X] Implement some kind of automatic queuing discipline.
      ANS: Not neccessary because of above.

*** PM
- [X] Debugging trace results
  - [X] Check eio-dump for the statx results to see if perfetto display is the problem
  - [X] Try using user data pointer instead of req pointer.
    ANS: req pointer is correct
  - [X] Check uring code/Linux version why fstatat is being used
    ANS: Used by readdir

** <2024-05-22 Wed>
*** AM
  - [X] Debugging trace
    - [X] See if there are other trace viewers for Fuchsia
      ANS: None
    - [X] Add kiocb to types to get opcode from req pointer
      ANS: Not worth the effort
    - [X] Test thomas's workload see if there's a speedup from cutting syscalls.

*** PM
  - [X] Optimizing uring performance
    - [X] Use batching
    - [X] Use SQE polling

** <2024-05-23 Thu>
  - [X] Improving tracing
    - [X] Fix nested calls (Needs separate tracks)

** <2024-05-24 Fri>
- [X] Improving trace visualization
  - [X] Implement flows
  - [X] Implement separate tracks for uring submission and completion queue
  - [X] Add flows to fxt writer library
  - [X] Understand and write about how uring works (detailing what happens exactly in the kernel)

** <2024-05-25 Sat>
- [X] Clean io-uring tracer repo
- [X] Cleaner separation of ocaml-libbpf and iouring_tracer.

  ANS: libbpf are concerned with pure bindings, iouring_tracer has the
  bpf kernel program and can also bind arbritrary skel code or user
  custom structs

- [X] Work on bpf side to count events dropped.
- [X] Count number of events dropped and work on seeing how to overcome this

  ANS: Implemented counter to see how many events are dropped, by
  right, polling should be able to keep up until 1Mil ops/s. We don't
  hit that stat but somehow we are dropping events.


** <2024-05-28 Tue>
- [X] Write last weeks work

- [X] Continue building understanding how uring makes things
  asynchronous and think of better ways to visualize this
- [X] Debug dropped events or at least find a temporary solution

  ANS: Consumer seems to go 300,000 ops/sec (Could be because of
  caml_runtime_lock_acquire everytime during polling)

** <2024-05-29 Wed>
- [X] Set up automated way of having new tracks depending on the
  number of rings the user spawns (Wrapper of fxt)
** <2024-05-30 Thu>
  - [X] Write out todos and discussion for today
  - [X] Fix visualization

*** TODO <2024-05-23 Thu>
- [ ]  Benchmarks
  - [ ] Optimizing uring performance
    - [ ] Use fixed buffers
    - [ ] set IO_SQE_ASYNC flag on requests
  - [ ] Accessing files by path vs FD
  - [ ] Use linking vs non linking
  - [ ] Bench hybrid strategy, Using all cores versus some kind of split (in sqpoll mode)
  - [ ] eio benchmark http with sqpoll, can check that out.
  - [ ] Figure out why sqring_wait fails

- [-] Improving trace visualization
  - [X] Research io-uring execution model to plan out visualization
    (Check README.md in iouring_tracer_clean branch for notes)
  - [X] Better visualization of submit/complete
    - [X] Add support for FXT flow events and see how they display in perfetto
    - [X] Use separate tracks
  - [X] Investigate & fix dropped events
    - [X] Implement counter in bpf kernel side to count number of
      dropped events due to lack of space in ring buffer space.
      ANS: True, dropping due to inability to reserve space.
    - [X] Check producer & consumer rates
      ANS: Our OCaml consumer picks up request at 300,000 ops/s, on fs
      benchmarks, bpf can drive up to 800,000 ops/s (cold cache), even
      higher when files are in cache.

    - [X] Increase Ring buffer size
      ANS: helps slightly but catches up quite fast
    - [X] Theoretical benchmarks say that we should be able to
      accomodate just about 1M ops/s, but this is with a C handler,
      perhaps we are having overhead from runtime lock acquiring?
      ANS: Not really possible in a clean way

  - [X] Add dynamic track creation in FXT

  - [X] Support other tracepoints
    - [X] io_uring_queue_async_work
    - [X] io_uring_create

  - [X] Cleaning up bpf code
    - [X] Abstract out reusable functions

  - [-] Make ocaml_libbpf more ergonomic
    - [X] Implement more core low-level bindings
    - [ ] Write high-level easy to use wrappers

**** Discussion
- In OCaml, I get the same pid for multiple OCaml domains, is that expected?
ANS: domains have different tids but same pids.

- Portability, vmlinux.h are specific to kernel version, but we have
  to rewrite them into userspace with arbritrary types?
- C types are a range, long is at least 32 bit, etc. Then how do we
  ensure the types are consistent?
  ANS: Yes this will be a problem, use <stdint.h>



* NEXT Meeting
** TODO <2024-05-30 Thu>
- [ ] iouring_tracer tool
  - [ ] Implement ctypes skel code for easier handling of bpf code
    Experimented but was hard to glue together, initial work in skel directory
  - [ ] Add leftover tracepoint visualizations (fxt writing)
  - [ ] Load pids to trace from OCaml program to bpf map.
  - [ ] Implement sampling option, use some kind of a hash to mark if
    a request should be kept or not (or modulus of request)
  - [ ] Check how to publish a binary for iouring-tracer
  - [ ] Fix to <stdint.h> types

- [ ] ocaml-libbpf library
  - [ ] Write high-level easy to use interface
  - [ ] Work on publishing ocaml-libbpf (check if libbpf needs to be built alongside the kernel)


** IO-uring under the hood
IO-uring is a subsystem implemented in the Linux kernel that provides
"generic"and "true" asynchronous API's for IO. The late posix aio
interface was criticised to be asynchronous only sometimes and useful
only for storage IO.

At the heart of it, io-uring is implemented with two ring buffers that
are shared by the kernel and the user application. One ring is called
the submission queue ring where the user application puts IO requests
for the kernel to consume. The other is called the completion queue
ring which is where the kernel puts the results of the requests and is
consumed by the application.

Between the time the kernel consumes the requests and returns the
results, io-uring makes various 'smart' decisions on how your IO
should be handled asynchronously. There are notable 3 pathways a
request can take when handled in the kernel.

User Space:                          Kernel Space:
  ┌─────────────────────────────┐      ┌─────────────────────────────┐
  │io_uring_enter()             │      │io_uring_enter()             │
  └─────────────────────────────┘      └─────────────────────────────┘
         │                                  │
         │                                  │
         ▼                                  │
  ┌─────────────────────────────┐           │
  │Submit SQEs to SQ ring       │           │
  └─────────────────────────────┘           ▼
         │                                  │
         ▼                                  ▼
  ┌─────────────────────────────┐    ┌─────────────────────────────┐
  │Process SQEs                 │    │io_submit_sqes()              │
  └─────────────────────────────┘    └─────────────────────────────┘
         │                                  │
         │                                  │
         ▼                                  ▼
  ┌─────────────────────────────┐    ┌─────────────────────────────┐
  │Queue SQE for execution      │    │io_queue_sqe()                │
  └─────────────────────────────┘    └─────────────────────────────┘
         │                                  │
         │                                  │
         ▼                                  ▼
  ┌─────────────────────────────┐    ┌─────────────────────────────┐
  │Execute I/O Operation        │    │io_read(), io_write(), etc.   │
  └─────────────────────────────┘    └─────────────────────────────┘
         │                                  │
         │                                  │
         ▼                                  ▼
  ┌─────────────────────────────┐    ┌─────────────────────────────┐
  │Fill Completion Queue (CQ)   │    │io_cqring_fill_event()        │
  └─────────────────────────────┘    └─────────────────────────────┘
         │                                  │
         │                                  │
         ▼                                  ▼
  ┌─────────────────────────────┐    ┌─────────────────────────────┐
  │Check Completion Queue (CQ)  │    │io_get_cqe()                  │
  └─────────────────────────────┘    └─────────────────────────────┘

io_queue_sqe() is where the main decision making occurs. Here, it
checks whether your IO request can be handled immediately (meaning
that it is ready, think about data on a socket). In which case, it
runs directly without blocking. This is the fast path.

If data is not ready to be consumed, then uring either arms a poll on
the file descriptor to wait to be notified, or passes this off to a
worker pool of threads that pick up the request and get blocked (this
changed recently to support internally performing a poll).

Questions:
- Find out where io_op_def->issue is defined and what it contains.
- What is task work?

*** Notes:
- The SQ limit is half of the max CQ entries, presumably to prevent
  blocking when the kernel is processing a submission request and the
  user application wants to submit another request.

- Potential optimization:
  - If we know that operations are going to punt off to asynchronous
    calls, you can set IO_ASYNC_SQE flag on the request to remove
    checks that data is ready.

  - Use provided buffers to let the kernel allocate when data is ready
    instead of providing them during submission

  - Register fixed files to reduce fget, fput to kernel struct
    managing fds

** BPF ring buffer
- Ocaml consumer can't keep up, it has some overhead from acquiring
  the runtime lock, processes 300_000 ops/s
- bpf events are produced at spike to 800_000ops/s (on cold cache)
- 1.3Mops/s (when files are in cache)

bpf/
bpf-helpers.h
bpf-tracing.h
bpf-core.h
- are for bpf kernel code

libbpf.h
are exposed to userspace for use

* Backlog:
** Tracing analysis
- [ ] Implement spawning more worker threads
- [ ] write a test suite to check the number of processes, threads and
  io-workers for the given target
- [ ] show tasks sent for async request vs tasks sent for polling
- [ ] show completion events
- [ ] Convert eio benchmark program into a polling server.
- [ ] See what kind of performance bonus io_uring can maximally perform

** iouring_tracer
- [ ] Add graceful shutdown C-thread design
- [ ] Setup Co-RE, Replace <bpf/linux.h> with "vmlinux.h"
- [ ] Figure out how to separate running of the root bpf program and
  OCaml. Might need to be an external monitor like bpftrace
- [ ] Add custom events polling to bpftrace
- [ ] Add epoll method
- [ ] How does the Event module work?
- [ ] Check what low impact monitoring using C primatives for runtime
  events can do
- [ ] Potentially add USDT probes
- [ ] Runtime lock blocks until a poll point. This messes up the
  custom events timestamp, see if it's possible to extend custom
  events to support this
- [ ] Work towards packaging and giving a talk about the tool to the internal teams
- [ ] Work on getting the timestamping correct in custom events.
  - [ ] What is the semantics of caml_runtime_acquire_lock
  - [ ] See if it's possible to pass on timestamps
  - [ ] Check how often the runtime lock is being grabbed
  - [ ] See if you can buffer events

** Libbpf
- [ ] Wrap one function from libbpf using vendoring method
  - [ ] Check initial commit for liburing
  - [ ] How does compilation process work for simple C library.
    - [ ] Static
    - [ ] Dynamic
    - [ ] Includes
    - [ ] Headers


Hi Anil,

Thanks for the pointers! I've just got the BPF tracing tool minimally
working to capture syscalls and operations submitted to uring and
display them as time slices nicely with perfetto. With that, I'm
getting started on these benchmarks and had some questions around the
actual diffing algorithm that'll be useful for crafting the
benchmarks.

- "stat(2) vs statx(2)"
   What are the required fields?

- "io_uring linked requests vs independent requests"
  Shouldn't enforcing any kind of ordering on the requests be slower
  than arbritrary requests that can be submitted and complete
  independently? Unless the question here is about the performance
  benefit of handling the ordering in userland versus in-kernel?

- "also not clear how big the various buffers need to be."
  What kind of data are we storing in these buffers?

Our current plan is to write these test cases in C and use hyperfine
to get a high-level idea of their performance. Then we'll come in with
the BPF tool to understand what's happening in the kernel and use that
as feedback to add more features to the tool itself.
